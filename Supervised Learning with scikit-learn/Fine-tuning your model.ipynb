{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How good is your model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies</th>\n",
       "      <th>glucose</th>\n",
       "      <th>diastolic</th>\n",
       "      <th>triceps</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>dpf</th>\n",
       "      <th>age</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnancies  glucose  diastolic  triceps  insulin   bmi    dpf  age  \\\n",
       "0            6      148         72       35        0  33.6  0.627   50   \n",
       "1            1       85         66       29        0  26.6  0.351   31   \n",
       "2            8      183         64        0        0  23.3  0.672   32   \n",
       "3            1       89         66       23       94  28.1  0.167   21   \n",
       "4            0      137         40       35      168  43.1  2.288   33   \n",
       "\n",
       "   diabetes  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia = pd.read_csv('diabetes.csv')\n",
    "dia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['pregnancies', 'glucose', 'diastolic', 'triceps', 'insulin', 'bmi', 'dpf', 'age']\n",
    "\n",
    "y = dia['diabetes']\n",
    "\n",
    "X = dia.drop(['diabetes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176  30]\n",
      " [ 56  46]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80       206\n",
      "          1       0.61      0.45      0.52       102\n",
      "\n",
      "avg / total       0.71      0.72      0.71       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.4)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression and the ROC curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[175  31]\n",
      " [ 36  66]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.85      0.84       206\n",
      "          1       0.68      0.65      0.66       102\n",
      "\n",
      "avg / total       0.78      0.78      0.78       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
    "\n",
    "# Create the classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Compute and print the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to use logistic regression for binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting an ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'ROC Curve')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, threashold = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ROC curve provides a nice visual way to assess your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95783779, 0.87327321, 0.85281462, 0.8252915 , 0.80955787,\n",
       "       0.80245804, 0.79650877, 0.75688438, 0.75469702, 0.73770978,\n",
       "       0.73532821, 0.73198842, 0.72878757, 0.71803487, 0.70808483,\n",
       "       0.70407497, 0.70164731, 0.69587952, 0.69418249, 0.68360355,\n",
       "       0.67430385, 0.67425934, 0.66828024, 0.66777801, 0.65936274,\n",
       "       0.61420614, 0.61401966, 0.60981036, 0.59599999, 0.57244443,\n",
       "       0.57077545, 0.55565896, 0.54706775, 0.54448414, 0.54112471,\n",
       "       0.52003065, 0.51778948, 0.51464377, 0.48816705, 0.48727658,\n",
       "       0.48711989, 0.48396258, 0.45641938, 0.45006096, 0.44889851,\n",
       "       0.4421307 , 0.42818999, 0.42458005, 0.4213117 , 0.40757924,\n",
       "       0.40189105, 0.40091786, 0.37790293, 0.37575894, 0.36333115,\n",
       "       0.36277267, 0.36140952, 0.35727097, 0.35444268, 0.34759832,\n",
       "       0.33802383, 0.33766745, 0.3367104 , 0.33413563, 0.3174213 ,\n",
       "       0.31668728, 0.31543062, 0.31262927, 0.30942812, 0.30845251,\n",
       "       0.2870945 , 0.28642802, 0.28470851, 0.28110944, 0.27800997,\n",
       "       0.27262589, 0.25829123, 0.25296151, 0.24656272, 0.23839137,\n",
       "       0.21462178, 0.21419475, 0.20494834, 0.20460595, 0.19707906,\n",
       "       0.19631703, 0.18459249, 0.18269643, 0.16431395, 0.16347374,\n",
       "       0.15605919, 0.1560495 , 0.15591996, 0.15297351, 0.01409635])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00485437, 0.00485437, 0.00970874,\n",
       "       0.00970874, 0.01456311, 0.01456311, 0.01941748, 0.01941748,\n",
       "       0.02427184, 0.02427184, 0.02912621, 0.02912621, 0.03398058,\n",
       "       0.03398058, 0.04368932, 0.04368932, 0.04854369, 0.04854369,\n",
       "       0.05339806, 0.05339806, 0.0631068 , 0.0631068 , 0.07281553,\n",
       "       0.07281553, 0.0776699 , 0.0776699 , 0.09223301, 0.09223301,\n",
       "       0.09708738, 0.09708738, 0.11165049, 0.11165049, 0.12135922,\n",
       "       0.12135922, 0.12621359, 0.12621359, 0.16990291, 0.16990291,\n",
       "       0.17475728, 0.17475728, 0.2038835 , 0.2038835 , 0.20873786,\n",
       "       0.20873786, 0.22330097, 0.22330097, 0.22815534, 0.22815534,\n",
       "       0.24757282, 0.24757282, 0.27184466, 0.27184466, 0.2815534 ,\n",
       "       0.2815534 , 0.28640777, 0.28640777, 0.30097087, 0.30097087,\n",
       "       0.32038835, 0.32038835, 0.32524272, 0.32524272, 0.36407767,\n",
       "       0.36407767, 0.37378641, 0.37378641, 0.39320388, 0.39320388,\n",
       "       0.42718447, 0.42718447, 0.43203883, 0.43203883, 0.44660194,\n",
       "       0.44660194, 0.49029126, 0.49029126, 0.51941748, 0.51941748,\n",
       "       0.58737864, 0.58737864, 0.61165049, 0.61165049, 0.63592233,\n",
       "       0.63592233, 0.69902913, 0.69902913, 0.76213592, 0.76213592,\n",
       "       0.78640777, 0.78640777, 0.79126214, 0.79126214, 1.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00980392, 0.02941176, 0.02941176, 0.05882353, 0.05882353,\n",
       "       0.06862745, 0.06862745, 0.14705882, 0.14705882, 0.19607843,\n",
       "       0.19607843, 0.21568627, 0.21568627, 0.24509804, 0.24509804,\n",
       "       0.25490196, 0.25490196, 0.2745098 , 0.2745098 , 0.32352941,\n",
       "       0.32352941, 0.33333333, 0.33333333, 0.34313725, 0.34313725,\n",
       "       0.46078431, 0.46078431, 0.48039216, 0.48039216, 0.53921569,\n",
       "       0.53921569, 0.56862745, 0.56862745, 0.57843137, 0.57843137,\n",
       "       0.62745098, 0.62745098, 0.64705882, 0.64705882, 0.65686275,\n",
       "       0.65686275, 0.66666667, 0.66666667, 0.68627451, 0.68627451,\n",
       "       0.69607843, 0.69607843, 0.71568627, 0.71568627, 0.74509804,\n",
       "       0.74509804, 0.75490196, 0.75490196, 0.76470588, 0.76470588,\n",
       "       0.7745098 , 0.7745098 , 0.79411765, 0.79411765, 0.81372549,\n",
       "       0.81372549, 0.82352941, 0.82352941, 0.83333333, 0.83333333,\n",
       "       0.84313725, 0.84313725, 0.85294118, 0.85294118, 0.8627451 ,\n",
       "       0.8627451 , 0.87254902, 0.87254902, 0.89215686, 0.89215686,\n",
       "       0.90196078, 0.90196078, 0.91176471, 0.91176471, 0.93137255,\n",
       "       0.93137255, 0.94117647, 0.94117647, 0.95098039, 0.95098039,\n",
       "       0.96078431, 0.96078431, 0.97058824, 0.97058824, 0.98039216,\n",
       "       0.98039216, 0.99019608, 0.99019608, 1.        , 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recall of 1 corresponds to a classifier with a low threshold in which all females who contract diabetes were correctly classified as such, at the expense of many misclassifications of those who did not have diabetes.\n",
    "\n",
    "    This is actually a true statement! Observe how when the recall is high, the precision drops.\n",
    "\n",
    "Precision is undefined for a classifier which makes no positive predictions, that is, classifies everyone as not having diabetes.\n",
    "    \n",
    "    In the case when there are no true positives or true negatives, precision is 0/0, which is undefined.\n",
    "\n",
    "\n",
    "When the threshold is very close to 1, precision is also 1, because the classifier is absolutely certain about its predictions.\n",
    "\n",
    "    This is a correct statement. Notice how a high precision corresponds to a low recall: The classifier has a \n",
    "    high threshold to ensure the positive predictions it makes are correct, which means it may miss some positive labels that have lower probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8266228821625738\n",
      "AUC scores computed using 5-fold cross-validation: [0.7987037  0.80796296 0.81944444 0.86603774 0.85132075]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute and print AUC score\n",
    "print(\"AUC: {}\".format(roc_auc_score(y_test,y_pred_prob)))\n",
    "\n",
    "# Compute cross-validated AUC scores: cv_auc\n",
    "cv_auc = cross_val_score(logreg, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Print list of AUC scores\n",
    "print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 268.2695795279727}\n",
      "Best score is 0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Setup the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space}\n",
    "\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a 'C' of 268.27 results in the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning with RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 4}\n",
      "Best score is 0.7395833333333334\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from scipy.stats import randint\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Setup the parameters and distributions to sample from: param_dist\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": randint(1, 9),\n",
    "              \"min_samples_leaf\": randint(1, 9),\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# Instantiate a Decision Tree classifier: tree\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object: tree_cv\n",
    "tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "tree_cv.fit(X,y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\n",
    "print(\"Best score is {}\".format(tree_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out set in practice I: Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 31.622776601683793, 'penalty': 'l2'}\n",
      "Tuned Logistic Regression Accuracy: 0.7673913043478261\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.4, random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-out set in practice II: Regression\n",
    "\n",
    "Lasso used the L1 penalty to regularize, while ridge used the L2 penalty. In elastic net regularization, the penalty term is a linear combination of the L1 and L2 penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame: df\n",
    "df = pd.read_csv('gapminder.csv')\n",
    "\n",
    "# Create arrays for features and target variable\n",
    "y = df.life\n",
    "X = df.drop(['life', 'Region'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakan/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/hakan/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/hakan/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/hakan/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/hakan/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned ElasticNet l1 ratio: {'l1_ratio': 0.20689655172413793}\n",
      "Tuned ElasticNet R squared: 0.8668305372460283\n",
      "Tuned ElasticNet MSE: 10.057914133398441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 30)\n",
    "param_grid = {'l1_ratio': l1_space}\n",
    "\n",
    "# Instantiate the ElasticNet regressor: elastic_net\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Setup the GridSearchCV object: gm_cv\n",
    "gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "gm_cv.fit(X_train,y_train)\n",
    "\n",
    "# Predict on the test set and compute metrics\n",
    "y_pred = gm_cv.predict(X_test)\n",
    "r2 = gm_cv.score(X_test, y_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\n",
    "print(\"Tuned ElasticNet R squared: {}\".format(r2))\n",
    "print(\"Tuned ElasticNet MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
